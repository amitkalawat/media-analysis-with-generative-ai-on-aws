{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "inserted-a07d5c3b-8f7f-41c0-8aa8-c5c7e4e1c7e3",
   "metadata": {},
   "source": [
    "# Film Analysis Agent with Strands Agents SDK\n",
    "\n",
    "## Overview\n",
    "In this notebook, we'll rebuild the Film Agent using the [Strands Agents SDK](https://github.com/strands-agents/sdk-python?tab=readme-ov-file), an open source framework that takes a model-driven approach to building and running AI agents in just a few lines of code. Strands simplifies agent development by embracing the capabilities of state-of-the-art models to plan, chain thoughts, call tools, and reflect.\n",
    "\n",
    "We'll implement the same functionality as in the original notebook but using the Strands Agents SDK, which is already used in production by several AWS teams including Amazon Q Developer, AWS Glue, and VPC Reachability Analyzer.\n",
    "\n",
    "We'll explore:\n",
    "1. Creating an agent with knowledge base integration\n",
    "2. Implementing direct function integration for celebrity detection\n",
    "3. Setting up MCP-based tools for better separation of concerns\n",
    "\n",
    "<div class=\"alert-warning\">\n",
    "    <b>Warning:</b> you need to complete module 2 first because some resources like knowledge base are created in that module.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdf066b-c7a2-44f9-b344-f458283bab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from boto3.dynamodb.conditions import Key, Attr\n",
    "import os\n",
    "\n",
    "# Import strands-agents components\n",
    "from strands import Agent, tool\n",
    "from strands.tools.mcp import MCPClient\n",
    "from strands_tools import use_llm, memory\n",
    "from mcp import stdio_client, StdioServerParameters\n",
    "import json_repair\n",
    "\n",
    "# Initialize AWS clients\n",
    "boto3_session = boto3.Session()\n",
    "dynamodb_resource = boto3_session.resource('dynamodb')\n",
    "rek_client = boto3_session.client('rekognition')\n",
    "bedrock_agent_runtime = boto3_session.client('bedrock-agent-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21f577d-be44-4054-bf2a-5f7cb4cfa9ff",
   "metadata": {},
   "source": [
    "## Loading Configuration\n",
    "\n",
    "First, let's load the configuration from the previous modules, including knowledge base name, agent instructions, and other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51077fcd-cca5-4310-8188-9540a0e24b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r knowledge_base_name\n",
    "%store -r kb_config\n",
    "%store -r agent_instruction\n",
    "%store -r agent_name\n",
    "%store -r video_analysis\n",
    "%store -r cast_table\n",
    "%store -r cast_pk\n",
    "%store -r film_video_s3_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f798bc",
   "metadata": {},
   "source": [
    "## Multiple Model Providers\n",
    "Strands SDK takes a model-driven approach and offers flexible model support. It can run anywhere and supports any model with reasoning and tool use capabilities, including models from Amazon Bedrock, Anthropic, Meta, Ollama, and other providers through LiteLLM.\n",
    "\n",
    "Like the two strands of DNA, Strands connects two core pieces of the agent together: the model and the tools. Strands plans the agent's next steps and executes tools using the advanced reasoning capabilities of models.\n",
    "\n",
    "<div class=\"alert-info\">\n",
    "    <b>INFO:</b> Uncomment the code below to try other model providers. Please remember to set your API key in the environment variable\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df581645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands.models import BedrockModel\n",
    "# from strands.models.ollama import OllamaModel\n",
    "# from strands.models.llamaapi import LlamaAPIModel\n",
    "\n",
    "# Bedrock\n",
    "bedrock_model = BedrockModel(\n",
    "  model_id=\"us.anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
    "  temperature=0.1,\n",
    ")\n",
    "agent = Agent(model=bedrock_model)\n",
    "agent(\"Tell me about Agentic AI\")\n",
    "\n",
    "# # Ollama\n",
    "# ollama_modal = OllamaModel(\n",
    "#   host=\"http://localhost:11434\",\n",
    "#   model_id=\"llama3\"\n",
    "# )\n",
    "# agent = Agent(model=ollama_modal)\n",
    "# agent(\"Tell me about Agentic AI\")\n",
    "\n",
    "# # Llama API\n",
    "# llama_model = LlamaAPIModel(\n",
    "#     model_id=\"Llama-4-Maverick-17B-128E-Instruct-FP8\",\n",
    "# )\n",
    "# agent = Agent(model=llama_model)\n",
    "# response = agent(\"Tell me about Agentic AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowledge-base-section",
   "metadata": {},
   "source": [
    "## Python-Based Tools\n",
    "\n",
    "In Strands' model-driven approach, tools are key to how you customize the behavior of your agents. Tools can retrieve relevant documents from a knowledge base, call APIs, run Python logic, or return static strings with additional model instructions.\n",
    "\n",
    "You can easily define tools using Python decorators or just leveraging existing tools available, which is one of the core concepts of Strands Agents. Compared with frameworks that require complex workflows, Strands simplifies agent development by letting the model drive tool selection and execution.\n",
    "\n",
    "### Creating a Basic Agent with Knowledge Base\n",
    "\n",
    "Now, let's create a basic agent that can answer questions using the knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c9139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set an environment variable for kb\n",
    "os.environ[\"STRANDS_KNOWLEDGE_BASE_ID\"] = kb_config['kb_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f09c404",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"which film is directed by Curtis Clark\"\n",
    "\n",
    "@tool\n",
    "def retrieve_kb(query:str)->str:\n",
    "    \"\"\"Process a user query with the knowledge base agent.\"\"\"\n",
    "    agent = Agent(tools=[memory, use_llm])\n",
    "\n",
    "    # Optimized retrieval parameters\n",
    "    results = agent.tool.memory(\n",
    "        action=\"retrieve\", \n",
    "        query=query,\n",
    "        min_score=0.4,  # Set minimum relevance threshold\n",
    "        max_results=1   # Limit number of results\n",
    "    )\n",
    "\n",
    "    print(f\"Retrieved results: {str(results)}\")\n",
    "\n",
    "    # System prompt for generating answers from retrieved information\n",
    "    ANSWER_SYSTEM_PROMPT = \"\"\"\n",
    "    You are a helpful knowledge assistant that provides clear, concise answers \n",
    "    based on information retrieved from a knowledge base.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the result to a string to extract just the content text\n",
    "    result_str = str(result)\n",
    "    # Generate a clear, conversational answer using the retrieved information\n",
    "    return agent.tool.use_llm(\n",
    "        prompt=f\"User question: \\\"{query}\\\"\\n\\nInformation from knowledge base:\\n{result_str}\\n\\nStart your answer with newline character and just answer the question directly:\",\n",
    "        system_prompt=ANSWER_SYSTEM_PROMPT\n",
    "    )\n",
    "\n",
    "retrieve_kb(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-function-section",
   "metadata": {},
   "source": [
    "### Create another tool to look up cast and role\n",
    "\n",
    "Let's implement another tool that can look up celebrites's role in the movie from dynamoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ae1207-7f83-4c54-86e3-6b220cff3363",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_cast_member(cast_id):\n",
    "    \"\"\"Query DynamoDB to get cast member information.\"\"\"\n",
    "    try:\n",
    "        table = dynamodb_resource.Table(cast_table)\n",
    "        key_expression = Key(cast_pk).eq(cast_id)\n",
    "        query_data = table.query(\n",
    "                KeyConditionExpression=key_expression\n",
    "            )\n",
    "        return query_data['Items']\n",
    "    except Exception as e:\n",
    "        print(f'Error querying table: {cast_table}.')\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559c9e2a-2700-4b64-bb40-2bf1661de135",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(model=bedrock_model, tools=[retrieve_kb, get_cast_member])\n",
    "response = agent(\"Can you tell me Kevin Kilner's role (id: 4kn3Xu8r) in th film `Meridian`?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3837b936-f765-40f9-a010-d3bab0dd57dc",
   "metadata": {},
   "source": [
    "## Built-in MCP Support\n",
    "Strands SDK provides native support for Model Context Protocol (MCP) servers, enabling access to thousands of published MCP servers that can be used as tools for your agent. This is particularly useful for complex agent use cases where you need specialized tools.\n",
    "\n",
    "Strands has published its own MCP server that you can use with any MCP-enabled development tool, such as the Q Developer CLI or Cline. This makes it easy to start building new agents today with your favorite AI-assisted development tool.\n",
    "\n",
    "You can also easily create your own MCP server by preparing a MCP server Python script like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mcp-server-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat key_figures_mcp_server.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mcp-client-section",
   "metadata": {},
   "source": [
    "### Setting Up MCP Client\n",
    "\n",
    "Now, let's set up the MCP client to connect to our server.\n",
    "\n",
    "<div class=\"alert-warning\">\n",
    "    <b>Warning:</b> This MCP server may take up to 5 minutes to run. because of rekignition video API for celebrity detection.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bea532-83d7-4b19-86bc-e91104056f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get AWS credentials for the MCP server\n",
    "def get_credentials():\n",
    "    credentials = boto3_session.get_credentials()\n",
    "    frozen_creds = credentials.get_frozen_credentials()\n",
    "    region = boto3_session.region_name\n",
    "    \n",
    "    return {\n",
    "        \"AWS_ACCESS_KEY_ID\": frozen_creds.access_key,\n",
    "        \"AWS_SECRET_ACCESS_KEY\": frozen_creds.secret_key,\n",
    "        \"AWS_DEFAULT_REGION\": region\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e34509",
   "metadata": {},
   "source": [
    "For this query, the agent will first look up the film, and then use the informaiton to detect the celebrity and lookup their role in the film."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8149e2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define MCP stdio parameters\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"python\",\n",
    "    args=[\n",
    "        \"key_figures_mcp_server.py\",\n",
    "    ],\n",
    "    env={\"CAST_TABLE\": cast_table, \"CAST_PK\":cast_pk, **get_credentials()},\n",
    ")\n",
    "# Create MCP client\n",
    "mcp_client = MCPClient(\n",
    "    lambda: stdio_client(server_params)\n",
    ")\n",
    "\n",
    "with mcp_client:\n",
    "   agent = Agent(tools=[retrieve_kb] + mcp_client.list_tools_sync())\n",
    "   response = agent(f\"\"\"\n",
    "    Here is a clip extraction:\n",
    "    {video_analysis}\n",
    "\n",
    "    if needed, here is the s3 location of the video:\n",
    "    {film_video_s3_path}\n",
    "    can you tell me which film is this clip from?\n",
    "    \"\"\")\n",
    "   additional_info = response.message['content'][0]['text'].strip()\n",
    "   print(additional_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdae0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store additional_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion-section",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to use the Strands Agents SDK to build a film analysis agent with the same functionality as the original implementation. We've shown:\n",
    "\n",
    "1. **Basic Agent with Knowledge Base**: Using Strands to create an agent that can answer questions about films using a knowledge base.\n",
    "\n",
    "2. **Direct Function Integration**: Implementing celebrity detection as a direct tool function that the agent can use.\n",
    "\n",
    "3. **MCP Integration**: Setting up an MCP server and client to provide the same functionality with better separation of concerns.\n",
    "\n",
    "The Strands Agents SDK provides a clean, intuitive interface for building AI agents that scales from simple to complex use cases, and from local development to deployment in production. Running agents in production is a key tenet for the design of Strands, which includes a deployment toolkit with reference implementations to help you take your agents to production.\n",
    "\n",
    "Strands is flexible enough to support a variety of architectures in production, whether you want to run your agent locally, behind an API, or in a distributed environment with tools running in separate backends."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
