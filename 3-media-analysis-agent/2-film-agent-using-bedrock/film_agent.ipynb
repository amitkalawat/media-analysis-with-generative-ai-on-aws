{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e9eb578-cd35-44b6-8230-80b0f08c2526",
   "metadata": {},
   "source": [
    "Film Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2ecf9f",
   "metadata": {},
   "source": [
    "# Building an AI Film Analysis Agent\n",
    "\n",
    "## Business Objective\n",
    "\n",
    "This notebook guides you through building an AI agent specialized in film analysis using AWS services. Before creating the agent itself, we first use Bedrock Data Automation (BDA) to analyze video content and extract key information. The agent then combines this analysis with a knowledge base of film information and celebrity recognition to automatically identify and analyze film content.\n",
    "\n",
    "Media companies need to efficiently process and identify film content across their large libraries. By deploying an AI agent, tasks that traditionally required hours of manual review - like identifying clips, recognizing actors, and extracting metadata - can be automated. This automation helps production teams work more efficiently and helps distribution teams better manage their content.\n",
    "\n",
    "## Main Steps\n",
    "\n",
    "### 1. Video Analysis with BDA\n",
    "We begin by using Bedrock Data Automation to analyze our video content. This involves:\n",
    "- Setting up a BDA project with specific video analysis configurations\n",
    "- Uploading video content for processing\n",
    "- Extracting rich metadata including transcripts, summaries, and scene analysis\n",
    "This initial analysis provides the structured data our agent will use to understand and identify film content.\n",
    "\n",
    "### 2. Knowledge Base Creation \n",
    "Next, we build a knowledge base containing film information. We upload film data to S3, configure vector search capabilities, and synchronize the data. This knowledge base gives our agent the background information it needs to match video content with specific films.\n",
    "\n",
    "### 3. Film Agent Development\n",
    "At this stage, we create the AI agent itself using Amazon Bedrock. We configure the agent with specific instructions for film analysis and connect it to the knowledge base. The agent uses foundation models to understand and analyze film content, enabling it to match clips to their source films.\n",
    "\n",
    "### 4. Celebrity Detection Integration\n",
    "We enhance the agent's capabilities by adding celebrity detection. Using a Lambda function and DynamoDB, we enable the agent to recognize actors in video clips and retrieve information about their roles. This feature helps confirm film identification through cast appearance.\n",
    "\n",
    "### 5. Testing and Validation\n",
    "We thoroughly test the agent's capabilities, including:\n",
    "- Searching the knowledge base for film information\n",
    "- Detecting and identifying celebrities in video clips  \n",
    "- Running complete film identification workflows\n",
    "\n",
    "These tests ensure the agent can accurately identify films using both content analysis and cast recognition.\n",
    "\n",
    "### 6. Production Preparation\n",
    "Finally, we prepare the agent for production use by:\n",
    "- Creating a stable agent alias\n",
    "- Saving all configuration information\n",
    "- Setting up proper resource management\n",
    "\n",
    "This notebook shows you how to combine AWS AI services to create a practical solution for film content identification and analysis. The resulting agent helps media companies automate content processing while maintaining accuracy and consistency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211e4a3b-f2b7-4c05-84c7-3afc65b0cc73",
   "metadata": {},
   "source": [
    "#### > Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0855789b-5008-4bf6-ac3b-c06807db625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8de735",
   "metadata": {},
   "source": [
    "### Analyze and extract video\n",
    "\n",
    "Before building our agent, we first need to analyze the video content to extract meaningful information. We'll use Amazon Bedrock Data Automation (BDA) which provides powerful AI capabilities for video analysis.\n",
    "\n",
    "In this section, we first set up the required AWS services and then create a BDA project configured for video analysis. The project will extract several types of information from our video:\n",
    "- A comprehensive video summary\n",
    "- Scene-by-scene analysis\n",
    "- Full audio transcript \n",
    "- Text detected in the video\n",
    "- Scene classifications\n",
    "\n",
    "This extracted information will serve as the foundation for our agent's ability to identify and analyze film content. Let's start by configuring the necessary AWS clients and resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4013b57",
   "metadata": {},
   "source": [
    "First of all let's initialize the environment for video analysis using AWS services. The following setup will prepare the variables to create a Bedrock Data Automation project, upload a video file, and extract insights from it using AWS's AI services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0372b5-d90a-4b16-9bb8-82e91066adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import uuid\n",
    "import sagemaker\n",
    "import uuid\n",
    "\n",
    "boto_session = boto3.session.Session()\n",
    "sess = sagemaker.Session(boto_session=boto_session)\n",
    "if sess.default_bucket():\n",
    "    bucket = sess.default_bucket()\n",
    "else:\n",
    "    bucket = \"<YOUR-BUCKET-NAME>\" # Provide your own bucket\n",
    "region = sess.boto_region_name\n",
    "prefix = \"media-operations-agent-claude\"\n",
    "\n",
    "bda_client = boto_session.client('bedrock-data-automation')\n",
    "bda_runtime_client = boto_session.client('bedrock-data-automation-runtime')\n",
    "s3_client = boto_session.client('s3')\n",
    "\n",
    "#access account id\n",
    "sts_client = boto_session.client('sts')\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "\n",
    "default_profile_arn = f\"arn:aws:bedrock:{region}:{account_id}:data-automation-profile/us.data-automation-v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e689820-6d96-4016-94bf-048cda62d52e",
   "metadata": {},
   "source": [
    "### Prepare the sample video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efb6a82-f6f0-4ce4-9058-b7a165912c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file = 'NetflixMeridian.mp4'\n",
    "!curl \"https://ws-assets-prod-iad-r-pdx-f3b3f9f1a7d6a3d0.s3.us-west-2.amazonaws.com/7db2455e-0fa6-4f6d-9973-84daccd6421f/Netflix_Open_Content_Meridian.mp4\" --output NetflixMeridian.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e23c03-2f91-4dc7-b277-63521a55529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_key = f\"{prefix}/{video_file}\"\n",
    "\n",
    "s3_client.upload_file(video_file, bucket, s3_key)\n",
    "film_video_s3_path = f\"s3://{bucket}/{s3_key}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d1cc8a-5712-4ed3-bd1e-6062b3452f9f",
   "metadata": {},
   "source": [
    "### Create a BDA project\n",
    "\n",
    "To analyze our film content, we first need to create a Bedrock Data Automation (BDA) project. This project will define what information we want to extract from our video and how it should be processed.\n",
    "\n",
    "A BDA project organizes both standard and custom output configurations, making it reusable across multiple videos that need similar analysis. For our film analysis agent, we'll configure the project to extract:\n",
    "- Full video summary: A comprehensive overview of the video content\n",
    "- Scene summaries: Detailed analysis of individual scenes\n",
    "- Audio transcript: Complete transcription of spoken content\n",
    "- Text detection: Identification of text visible in the video\n",
    "\n",
    "In the code below, we create a BDA project with these configurations. Each extracted element will later help our agent:\n",
    "- Understand the film's plot and content (summaries)\n",
    "- Follow dialogue and narration (transcript)\n",
    "- Identify on-screen text that might indicate the film's source\n",
    "\n",
    "For a complete API reference for creating a BDA project, refer to this [document](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-data-automation/client/create_data_automation_project.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56412c10",
   "metadata": {},
   "source": [
    "The BDA project creation returns a project ARN (Amazon Resource Name), which we'll store in video_project_arn. We'll need this unique identifier later to invoke the video analysis task and track its progress.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea5039f-8ec1-4488-97c5-3f7d3ac7b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bda_client.create_data_automation_project(\n",
    "    projectName=f'{prefix}-{str(uuid.uuid4())[0:4]}',\n",
    "    projectDescription='Media operations agent',\n",
    "    projectStage='DEVELOPMENT',\n",
    "    standardOutputConfiguration={\n",
    "        'video': {\n",
    "            'extraction': {\n",
    "                'category': {\n",
    "                    'state': 'ENABLED',\n",
    "                    'types': ['TEXT_DETECTION','TRANSCRIPT'],\n",
    "                },\n",
    "                'boundingBox': {\n",
    "                    'state': 'DISABLED',\n",
    "                }\n",
    "            },\n",
    "            'generativeField': {\n",
    "                'state': 'ENABLED',\n",
    "                'types': ['VIDEO_SUMMARY','CHAPTER_SUMMARY','IAB'],\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "video_project_arn = response.get(\"projectArn\")\n",
    "print(\"BDA video project ARN:\", video_project_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7612d68-2817-412a-ac3b-bd21ab0a1147",
   "metadata": {},
   "source": [
    "### Extract analysis from video\n",
    "\n",
    "Now that our video is in S3, we can start the BDA analysis process. We'll use the invoke_data_automation_async API to launch an asynchronous analysis task. This task will process our video using the configurations we defined in our BDA project.\n",
    "\n",
    "The code below:\n",
    "1. Configures the input (our S3 video) and output locations\n",
    "2. References our BDA project for analysis settings\n",
    "3. Launches the analysis task\n",
    "4. Returns an invocation ARN that we'll use to track the task's progress\n",
    "\n",
    "This analysis will extract all the elements we need for our agent:\n",
    "- Video summaries\n",
    "- Scene analysis\n",
    "- Audio transcripts\n",
    "- Detected text\n",
    "\n",
    "Note that this is an asynchronous process - we'll monitnitor its progress in the next section. In a production environment, you might want to use event notifications instead of polling, but for this demonstration, we'll actively track the task's status.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5aa4ce-a340-4684-a35f-84f52f2b2213",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bda_runtime_client.invoke_data_automation_async(\n",
    "    inputConfiguration={\n",
    "        's3Uri': f's3://{bucket}/{s3_key}'\n",
    "    },\n",
    "    outputConfiguration={\n",
    "        's3Uri': f's3://{bucket}/{prefix}/outputs'\n",
    "    },\n",
    "    dataAutomationConfiguration={\n",
    "        'dataAutomationProjectArn': video_project_arn,\n",
    "        'stage': 'DEVELOPMENT'\n",
    "    },\n",
    "    notificationConfiguration={\n",
    "        'eventBridgeConfiguration': {\n",
    "            'eventBridgeEnabled': False\n",
    "        }\n",
    "    },\n",
    "    dataAutomationProfileArn=default_profile_arn\n",
    ")\n",
    "\n",
    "invocation_arn = response.get(\"invocationArn\")\n",
    "print(\"BDA task started:\", invocation_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698d161c-5d1a-462d-82d8-620a554eae6c",
   "metadata": {},
   "source": [
    "### Wait"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b10c884",
   "metadata": {},
   "source": [
    "Now that we've launched our BDA analysis task, we need to monitor its progress until completion. Since this is an asynchronous process, we'll implement a polling mechanism that checks the task status every few seconds.\n",
    "\n",
    "The code below:\n",
    "1. Creates a monitoring loop that calls get_data_automation_status\n",
    "2. Updates us with timestamps and current status\n",
    "3. Continues until the job reaches a final state (Success, ServiceError, or ClientError)\n",
    "4. Retrieves the S3 location of our analysis results upon completion\n",
    "\n",
    "The analysis typically takes 5-10 minutes to process the video. While polling works well for this demonstration, in a production environment you might prefer using AWS EventBridge notifications to trigger your next steps automatically when the analysis completes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b45407-bf86-4245-8a9b-e3fe323e76a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime\n",
    "\n",
    "status, status_response = None, None\n",
    "while status not in [\"Success\",\"ServiceError\",\"ClientError\"]:\n",
    "    status_response = bda_runtime_client.get_data_automation_status(\n",
    "        invocationArn=invocation_arn\n",
    "    )\n",
    "    status = status_response.get(\"status\")\n",
    "    clear_output(wait=True)\n",
    "    print(f\"{datetime.now().strftime('%H:%M:%S')} : BDA video task: {status}\")\n",
    "    time.sleep(5)\n",
    "\n",
    "output_config = status_response.get(\"outputConfiguration\",{}).get(\"s3Uri\")\n",
    "print(\"Ouput configureation file:\", output_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346d2465-3308-4f05-a57b-fbf98dfb6113",
   "metadata": {},
   "source": [
    "### Access the BDA Analysis Result\n",
    "\n",
    "Now that our video analysis is complete, we'll retrieve and structure the results for our agent to use. The BDA analysis provides rich information about our video content that will be crucial for film identification.\n",
    "\n",
    "First, we'll get the job metadata from the configuration file, which tells us where to find our detailed analysis results. Then, we'll fetch and organize this analysis data into a format our agent can effectively use.\n",
    "\n",
    "The BDA analysis provides comprehensive information about our video:\n",
    "- A detailed overall summary of the film's content\n",
    "- Scene-by-scene analysis and transitions\n",
    "- Complete audio transcription\n",
    "- Technical metadata about the video file\n",
    "\n",
    "This extracted information forms the foundation of our agent's ability to identify and analyze films. We'll store this data in a structured format that allows our agent to:\n",
    "- Match plot details against our knowledge base\n",
    "- Analyze scene content for film identification\n",
    "- Use transcripts to confirm dialogue matching\n",
    "- Leverage technical details for verification\n",
    "\n",
    "We'll use the IPython.display JSON viewer to explore this rich dataset, making it easier to understand the structure and content of our analysis results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283c2966-29b6-41c2-9023-115b8c3cc2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_on_s3(s3_uri, s3_client):\n",
    "    # Parse s3 bucket and key from s3 uri\n",
    "    s3_bucket = s3_uri.split('/')[2]\n",
    "    s3_key = s3_uri.replace(f's3://{s3_bucket}/','')\n",
    "    \n",
    "    # Read BDA output_config file on S3\n",
    "    response = s3_client.get_object(Bucket=s3_bucket, Key=s3_key)\n",
    "    file_content = response['Body'].read().decode('utf-8')  # Read the content and decode it to a string\n",
    "    # Convert the content to JSON\n",
    "    return json.loads(file_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eb00c7",
   "metadata": {},
   "source": [
    "The BDA output configuration file provides the S3 location where our analysis results are stored. First, let's read and display this configuration file to locate our results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5546c03a-696b-4b0e-92a6-ae7447b64031",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_data = read_json_on_s3(output_config,s3_client)\n",
    "print(json.dumps(config_data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed090722",
   "metadata": {},
   "source": [
    "As we can see, this configuration file contains metadata about our BDA analysis, including the job ID, status, and most importantly, the S3 path to our full analysis results. Now let's retrieve those detailed results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b26d39-d13b-47ec-9b18-0ac6f9640193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import JSON\n",
    "\n",
    "result_uri = config_data[\"output_metadata\"][0][\"segment_metadata\"][0][\"standard_output_path\"]\n",
    "result_data = read_json_on_s3(result_uri,s3_client)\n",
    "\n",
    "JSON(result_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd23ca74",
   "metadata": {},
   "source": [
    "Let's organize the most relevant information from our BDA analysis into a structured format for our agent, combining the visual summary, audio transcription, and technical metadata:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14015f94-f4c5-4e5b-8d9d-a682ae4aac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_analysis = {\n",
    "    \"visual_summary\": result_data[\"video\"][\"summary\"],\n",
    "    \"audio_transcription\":result_data[\"video\"][\"transcript\"][\"representation\"][\"text\"],\n",
    "    \"metadata\":result_data[\"metadata\"]\n",
    "    \n",
    "}\n",
    "video_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1038f3b-84f7-4106-a162-7c211ef8a6c7",
   "metadata": {},
   "source": [
    "## Setup Film Agent\n",
    "\n",
    "Now that we have our video analysis results, let's create an AI agent using Amazon Bedrock Agents. Bedrock Agents provide a powerful framework for building AI applications that can understand natural language, process information, and take actions using foundation models.\n",
    "\n",
    "In our case, we'll create an agent specialized in film analysis that can:\n",
    "- Process video content analysis\n",
    "- Search through film databases\n",
    "- Recognize celebrities in footage\n",
    "- Combine multiple sources of information to identify films\n",
    "\n",
    "### Why Use an Agent?\n",
    "Agents excel at orchestrating complex tasks that require multiple steps and different types of analysis. For film identification, our agent will:\n",
    "1. Analyze the video content we extracted with BDA\n",
    "2. Query a knowledge base of film information\n",
    "3. Use celebrity recognition to identify actors\n",
    "4. Combine these insights to make accurate film identifications\n",
    "\n",
    "This automated approach helps media companies process content more efficiently than manual review while maintaining high accuracy.\n",
    "\n",
    "In the following sections, we'll:\n",
    "- Initialize the AWS environment for our agent\n",
    "- Configure the agent with specific film analysis instructions\n",
    "- Set up foundation models for the agent to use\n",
    "\n",
    "For more information about Amazon Bedrock Agents and their capabilities, see the [Amazon Bedrock Agents documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/agents.html).\n",
    "\n",
    "Let's start by setting up the necessary AWS clients and configurations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e333873-0eeb-4e8c-b349-38d30dbed63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "account_id_suffix = account_id[:3]\n",
    "agent_suffix = f\"{region}-{account_id_suffix}\"\n",
    "\n",
    "bedrock_client = boto3.client('bedrock-runtime', region)\n",
    "\n",
    "agent_foundation_model = [\n",
    "    'us.anthropic.claude-3-5-sonnet-20241022-v2:0',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a965dd",
   "metadata": {},
   "source": [
    "### Configure Resource Names\n",
    "\n",
    "Before creating our agent, we need to set up unique identifiers for all the AWS resources we'll use. Following AWS naming best practices, we'll create standardized names that clearly identify our resources while maintaining consistency across our solution.\n",
    "\n",
    "We'll configure names for:\n",
    "1. The agent and its Lambda function\n",
    "   - Using region and account identifiers for uniqueness\n",
    "   - Following a consistent prefix pattern for related resources\n",
    "\n",
    "2. Knowledge base resources\n",
    "   - Creating a descriptive name and description\n",
    "   - Setting up an S3 bucket for film information storage\n",
    "\n",
    "3. Cast member database\n",
    "   - Defining DynamoDB table name and keys\n",
    "   - Maintaining naming consistency with other components\n",
    "\n",
    "This standardized naming approach helps us:\n",
    "- Easily identify related resources\n",
    "- Maintain clear resource organization\n",
    "- Enable proper resource management\n",
    "- Support future scaling of our solution\n",
    "\n",
    "Let's define these resource names:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c04f4f-6c34-4e2f-b5a7-4cc0b8426e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_name = f\"f-agent-{agent_suffix}\"\n",
    "lambda_name = f\"fn-f-agent-{agent_suffix}\"\n",
    "\n",
    "agent_role_name = f'AmazonBedrockExecutionRoleForAgents_{agent_name}'\n",
    "\n",
    "knowledge_base_name = f'{agent_name}-02'\n",
    "\n",
    "suffix = f\"{region}-{account_id}\"\n",
    "\n",
    "knowledge_base_description = \"KB containing information of all the films\"\n",
    "bucket_name = f'{agent_name}-{suffix}'\n",
    "\n",
    "cast_table = f'cast-table-{agent_suffix}'\n",
    "cast_pk = 'id'\n",
    "cast_sk = 'name'\n",
    "env_args = [cast_table, cast_pk, cast_sk]\n",
    "bucket_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af29e7d-bf93-44db-b608-dd25b9fdd943",
   "metadata": {},
   "source": [
    "### Importing helper functions\n",
    "\n",
    "On following section, we're adding `bedrock_agent_helper.py` and `knowledge_base_helper` on Python path, so the files can be recognized and their functionalities can be invoked.\n",
    "\n",
    "Now, you're going to import from helper classes `bedrock_agent_helper.py` and `knowledge_base_helper.py`.\n",
    " \n",
    "Those files contain helper classes totally focused on make labs experience smoothly. \n",
    "\n",
    "All interactions with Bedrock will be handled by these classes.\n",
    "\n",
    "Following are methods that you're going to invoke on this lab:\n",
    "\n",
    "On `agents.py`:\n",
    "- `create_agent`: Create a new agent and respective IAM roles\n",
    "- `add_action_group_with_lambda`: Create a lambda function and add it as an action group for a previous created agent\n",
    "- `create_agent_alias`: Create an alias for this agent\n",
    "- `invoke`: Execute agent\n",
    "\n",
    "On `knowledge_bases.py`:\n",
    "- `create_or_retrieve_knowledge_base`: Create Knowledge Base on Amazon Bedrock if it doesn't exist or get info about previous created.\n",
    "- `synchronize_data`: Read files on S3, convert text info into vectors and add that information on Vector Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccfef50-66b7-48c3-b364-66dc0fd3942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from helper.bedrock_agent_helper import (\n",
    "    AgentsForAmazonBedrock\n",
    ")\n",
    "from helper.knowledge_base_helper import (\n",
    "    KnowledgeBasesForAmazonBedrock\n",
    ")\n",
    "agents = AgentsForAmazonBedrock()\n",
    "kb = KnowledgeBasesForAmazonBedrock()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4d37db-ba9c-41de-bc03-d1a70d4a6592",
   "metadata": {},
   "source": [
    "## Create and Synchronize Knowledge Base\n",
    "\n",
    "For our film analysis agent to effectively identify movies, it needs access to accurate film information. Amazon Bedrock Knowledge Bases provides a fully managed solution that allows our agent to search and retrieve film details using natural language processing. \n",
    "\n",
    "### Why Use a Knowledge Base?\n",
    "Our agent needs to match video content with specific films by:\n",
    "- Finding films with similar plots\n",
    "- Verifying director and cast information\n",
    "- Confirming production details\n",
    "- Cross-referencing scene descriptions\n",
    "\n",
    "A knowledge base enables these capabilities by:\n",
    "- Storing structured film information\n",
    "- Providing fast, accurate search capabilities\n",
    "- Enabling natural language queries\n",
    "- Supporting context-aware responses\n",
    "\n",
    "### What We'll Build\n",
    "In this section, we'll:\n",
    "1. Create a knowledge base specialized for film information\n",
    "2. Upload our film data to S3\n",
    "3. Configure vector search capabilities for efficient matching\n",
    "4. Synchronize the data to make it available to our agent\n",
    "\n",
    "This knowledge base will serve as our agent's reference library, helping it accurately identify films based on the video analysis we performed earlier. Let's start by creating the knowledge base:\n",
    "\n",
    "\n",
    "**This creation process can take several minutes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c6127a-4ff2-4e91-bbc1-530b0a10837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "kb_id, ds_id = kb.create_or_retrieve_knowledge_base(\n",
    "    knowledge_base_name,\n",
    "    knowledge_base_description,\n",
    "    bucket_name\n",
    ")\n",
    "\n",
    "print(f\"Knowledge Base ID: {kb_id}\")\n",
    "print(f\"Data Source ID: {ds_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b975244-7a12-4e9f-8abc-18ef869417ef",
   "metadata": {},
   "source": [
    "### Upload Film Documents to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05dc834",
   "metadata": {},
   "source": [
    "Before our knowledge base can be used, we need to upload our film information to S3. We'll use the AWS S3 sync command to efficiently transfer our film documents to the cloud.\n",
    "\n",
    "Our film information is stored in two types of files:\n",
    "- Text files (.txt) containing film plots, descriptions, and details\n",
    "- Metadata files (.json) with structured information about directors, release dates, and other film attributes\n",
    "\n",
    "First, let's clean up any notebook checkpoints to ensure we only upload the essential files:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d379ae-d8fe-459a-8487-e639e73010dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf `find -type d -name .ipynb_checkpoints`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb92296a",
   "metadata": {},
   "source": [
    "Now we'll sync our film documents to the S3 bucket we created earlier. The sync command will:\n",
    "- Upload our film information files\n",
    "- Maintain the file structure\n",
    "- Only transfer new or modified files\n",
    "\n",
    "This uploaded content will form the basis of our knowledge base, providing our agent with the information it needs to identify films.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaf5b25-9817-4b56-98bc-d9cc65b0aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "films_folder = \"films\"\n",
    "\n",
    "!aws s3 sync {films_folder} s3://{bucket_name}/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b70659",
   "metadata": {},
   "source": [
    "Now we'll synchronize our uploaded film data with the knowledge base. Amazon Bedrock will:\n",
    "- Generate vector embeddings from our film documents\n",
    "- Create semantic indexes for efficient retrieval\n",
    "- Prepare the data for RAG (Retrieval Augmented Generation)\n",
    "\n",
    "This synchronization transforms our text-based film information into a format optimized for AI-powered searching. Once complete, our agent will be able to quickly find and retrieve relevant film information based on video content analysis.\n",
    "\n",
    "Let's initiate the synchronization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a857c9-641b-460d-93da-20eca0bf0cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sync knowledge base\n",
    "kb.synchronize_data(kb_id, ds_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6c9900",
   "metadata": {},
   "source": [
    "Let's get the knowledge base ARN - we'll need this unique identifier later when connecting our agent to our film information:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130dfa39-b7a1-4dcb-9df2-306fffab8246",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_info = kb.get_kb(kb_id)\n",
    "kb_arn = kb_info['knowledgeBase']['knowledgeBaseArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a7bcf7",
   "metadata": {},
   "source": [
    "Let's configure how our agent should use the knowledge base. These instructions will tell the agent to reference this database when it needs to verify film information against its video analysis:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc15b4-6e24-47dd-920a-ffb359649d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_config = {\n",
    "    'kb_id': kb_id,\n",
    "    'kb_instruction': \"\"\"Use this knowledge base when you need to look up title, director, and plot of a film\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f317b37-0e34-405f-86ff-1d39a1eecc56",
   "metadata": {},
   "source": [
    "## Creating Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770dc372",
   "metadata": {},
   "source": [
    "And now let's create and configure the film agent in Amazon Bedrock. \n",
    "\n",
    "Amazon Bedrock Agents offers you the ability to build and configure autonomous agents in your application.  With agents, you can automate tasks for your customers and answer questions for them. \n",
    "\n",
    "In this particular task we will create an instruction to analyze film videos or deriative of film videos and match it to the correct film title and identify key cast memebers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac88d215-4edc-4638-af92-47e17f4cd2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_description = \"\"\"You are a film analyst. You job is analyzing shorts or derivatives of \n",
    "films, like promo or trailer. Finding the matching film and identify key cast memebers.\"\"\"\n",
    "\n",
    "agent_instruction = \"\"\"\n",
    "Your task is to analyze film videos or deriative of film videos and match it to the correct\n",
    "film title and identify key cast memebers.\n",
    "\n",
    "Your capabilities include:\n",
    "<capabilities>\n",
    "- Matching video to correct film title\n",
    "- Identify key cast members\n",
    "</capabilities>\n",
    "\n",
    "Response style:\n",
    "<Response style>\n",
    "- Be helpful and solution-oriented\n",
    "- Use clear, non-technical language\n",
    "- Maintain natural conversation flow\n",
    "- Be concise yet informative\n",
    "- do not add extra information not required by the user\n",
    "</Response style>\n",
    "\"\"\"\n",
    "\n",
    "film_agent = agents.create_agent(\n",
    "    agent_name,\n",
    "    agent_description,\n",
    "    agent_instruction,\n",
    "    agent_foundation_model,\n",
    "    kb_arns=[kb_arn],\n",
    "    code_interpretation=False\n",
    ")\n",
    "time.sleep(20)\n",
    "film_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3cb468-164e-4c54-bb8b-9ab91adc32bc",
   "metadata": {},
   "source": [
    "### Associating knowledge base\n",
    "Now that we've created the agent, let's associate the previously created knowledge base to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2881fead-7624-4ac8-9531-e8d52f097ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents.associate_kb_with_agent(\n",
    "    film_agent[0],\n",
    "    kb_config['kb_instruction'],\n",
    "    kb_config['kb_id']\n",
    ")\n",
    "time.sleep(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee1b979-3888-4654-9aaf-151c3c1e01f0",
   "metadata": {},
   "source": [
    "## Test Knowledge Base W/ Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a97a14",
   "metadata": {},
   "source": [
    "Let's test our Knowledge Base with Agent we have just created.\n",
    "\n",
    "To do this, we will need to configure knowledge base search and establish detailed search parameters, including vector search configuration, implicit filtering, model selection and others. \n",
    "\n",
    "This configuration optimizes the knowledge base search for film identification by enabling filtering by director and using hybrid search to improve accuracy. The session state will be passed to the agent during invocation to control its behavior and search capabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16e1b89-f807-4412-8bbc-57f92aa2f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_state = {\n",
    "    'knowledgeBaseConfigurations': [\n",
    "            {\n",
    "                'knowledgeBaseId': kb_config['kb_id'],\n",
    "                'retrievalConfiguration': {\n",
    "                    'vectorSearchConfiguration': {\n",
    "                        'implicitFilterConfiguration': {\n",
    "                            'metadataAttributes': [\n",
    "                                {\n",
    "                                    'description': 'this is the name of the director',\n",
    "                                    'key': 'Director',\n",
    "                                    'type': 'STRING'\n",
    "                                },\n",
    "                            ],\n",
    "                            'modelArn': \"anthropic.claude-3-5-sonnet-20241022-v2:0\"\n",
    "                        },\n",
    "                        'numberOfResults': 1,\n",
    "                        'overrideSearchType': 'HYBRID'\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "        ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9afd607",
   "metadata": {},
   "source": [
    "In the following step we will test the agent's ability to search the knowledge base for film information. \n",
    "\n",
    "Let's invoke the agent with a specific query about films directed bu Curtis Clark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52567438-789d-41fb-97f2-73d18cd18159",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import uuid\n",
    "\n",
    "response = agents.invoke(\n",
    "    input_text=f\"which film is directored by Curtis Clark\", \n",
    "    agent_id=film_agent[0], \n",
    "    enable_trace=True,\n",
    "    session_id=str(uuid.uuid4()),\n",
    "    session_state=session_state\n",
    ")\n",
    "print(\"====================\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6586f7-50af-446f-b2f2-0fa824bef1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store knowledge_base_name\n",
    "%store kb_config\n",
    "%store agent_instruction\n",
    "%store agent_name\n",
    "%store video_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d6176-c4fd-4688-9786-4685d48db821",
   "metadata": {},
   "source": [
    "### Creating Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cd98ff",
   "metadata": {},
   "source": [
    "Now let's create a Lambda function that will be used by the agent to detect celebrities (actors) in video clips, which is essential for identifying films based on the appearance of known cast members.\n",
    "\n",
    "We will use Amazon Rekognition that makes it easy to automatically recognize tens of thousands of well-known personalities in images and videos using machine learning, as well as Amazon DynamoDB for retrieving additional information about detected celebrities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e308978-03fe-469e-9bc5-76f49949faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile detection.py\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from boto3.dynamodb.conditions import Key, Attr\n",
    "\n",
    "## DynamoDB parameters\n",
    "dynamodb_resource = boto3.resource('dynamodb')\n",
    "cast_table = os.getenv('cast_table')\n",
    "cast_pk = os.getenv('cast_pk')\n",
    "\n",
    "## Rekognition parameters\n",
    "rek_client = boto3.client('rekognition')\n",
    "\n",
    "def get_named_parameter(event, name):\n",
    "    try:\n",
    "        return next(item for item in event['parameters'] if item['name'] == name)['value']\n",
    "    except StopIteration:\n",
    "        raise ValueError(f\"Required parameter '{name}' not found in event\")\n",
    "        \n",
    "def get_cast_member(cast_id):\n",
    "    try:\n",
    "        table = dynamodb_resource.Table(cast_table)\n",
    "        key_expression = Key(cast_pk).eq(cast_id)\n",
    "        query_data = table.query(\n",
    "                KeyConditionExpression=key_expression\n",
    "            )\n",
    "        return query_data['Items']\n",
    "    except Exception:\n",
    "        print(f'Error querying table: {cast_table}.')\n",
    "\n",
    "def start_celebrity_detection(bucket, video_key):\n",
    "    response = rek_client.start_celebrity_recognition(\n",
    "        Video={\n",
    "            'S3Object': {\n",
    "                'Bucket': bucket,\n",
    "                'Name': video_key\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    return response['JobId']\n",
    "\n",
    "def get_celebrity_detection_results(job_id):\n",
    "    response = rek_client.get_celebrity_recognition(JobId=job_id)\n",
    "    return response\n",
    "\n",
    "def extract_bucket_key(video_s3_path):\n",
    "    path = video_s3_path[5:]  # Remove 's3://'\n",
    "    bucket, key = path.split('/', 1)  # Split into bucket and key   \n",
    "    return bucket, key\n",
    "\n",
    "def detect_key_figures(video_s3_path):\n",
    "    bucket, key = extract_bucket_key(video_s3_path)\n",
    "    \n",
    "    job_id = start_celebrity_detection(bucket, key)\n",
    "    print(f\"Started celebrity detection job: {job_id}\")\n",
    "\n",
    "    while True:\n",
    "        response = get_celebrity_detection_results(job_id)\n",
    "        status = response['JobStatus']\n",
    "        \n",
    "        if status in ['SUCCEEDED', 'FAILED']:\n",
    "            print(\"JOB COMPLETE....\")\n",
    "            break\n",
    "        \n",
    "        print(\"Job in progress...\")\n",
    "        time.sleep(10)\n",
    "\n",
    "    unique_celebrities = {}  # Dictionary to store unique celebrities\n",
    "\n",
    "    if status == 'SUCCEEDED':\n",
    "        for celebrity in response['Celebrities']:\n",
    "            celeb = celebrity['Celebrity']\n",
    "            \n",
    "            # Only process celebrities with 95%+ confidence\n",
    "            if celeb['Confidence'] >= 95.0:\n",
    "                celeb_id = celeb['Id']\n",
    "                \n",
    "                # Store or update celebrity info only if not already stored\n",
    "                if celeb_id not in unique_celebrities:\n",
    "                    celebrity_info = {\n",
    "                        'name': celeb['Name'],\n",
    "                        'confidence': celeb['Confidence'],\n",
    "                        'id': celeb_id,\n",
    "                        'first_appearance': celebrity['Timestamp']\n",
    "                    }\n",
    "                    \n",
    "                    # If you have additional celebrity info in DynamoDB\n",
    "                    try:\n",
    "                        query_items = get_cast_member(celeb_id)\n",
    "                        if query_items:\n",
    "                            celebrity_info.update(query_items[0])\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error fetching additional celebrity info: {str(e)}\")\n",
    "                    \n",
    "                    unique_celebrities[celeb_id] = celebrity_info\n",
    "    else:\n",
    "        print(\"Detection failed....\")\n",
    "\n",
    "    # Convert the dictionary values to a list for the final output\n",
    "    final_output = list(unique_celebrities.values())\n",
    "    return final_output\n",
    "\n",
    "def populate_function_response(event, response_body):\n",
    "    return {\n",
    "        'response': {\n",
    "            'actionGroup': event['actionGroup'],\n",
    "            'function': event['function'],\n",
    "            'functionResponse': {\n",
    "                'responseBody': {\n",
    "                    'TEXT': {\n",
    "                        'body': str(response_body)\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "def lambda_handler(event, context):\n",
    "    print(event)\n",
    "    \n",
    "    function = event.get('function', '')\n",
    "    parameters = event.get('parameters', [])\n",
    "    video_s3_path = get_named_parameter(event, \"video_s3_path\")\n",
    "\n",
    "    if function == 'detect_key_figures':\n",
    "        result = detect_key_figures(video_s3_path)\n",
    "    else:\n",
    "        result = f\"Error, function '{function}' not recognized\"\n",
    "\n",
    "    response = populate_function_response(event, result)\n",
    "    print(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5547189",
   "metadata": {},
   "source": [
    "We will also need to define a function schema for the celebrity detection action. \n",
    "\n",
    "This schema serves as a contract between the agent and the Lambda function, defining what the function does and what inputs it requires. The agent will use this schema to understand when and how to call the function, and to validate that it has all the necessary information before making the call. This structured approach ensures reliable communication between the agent and the Lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0596db1-cc50-47a2-bce3-8606bc0ae8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions_def = [\n",
    "    {\n",
    "        \"name\": \"detect_key_figures\",\n",
    "        \"description\": \"\"\"Detect key figures (celebrity, cast member) from a video\n",
    "        and retrieve information about their position and team\"\"\",\n",
    "        \"parameters\": {\n",
    "            \"video_s3_path\": {\n",
    "                \"description\": \"S3 location of the video (e.g: s3://......)\",\n",
    "                \"required\": True,\n",
    "                \"type\": \"string\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54bf783-de09-4a1a-9c0b-e1123f0eceff",
   "metadata": {},
   "source": [
    "### Creating action group and attaching to the agent\n",
    "Now it's time to add this Lambda function and the function details as an action group for this agent and prepare it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a1dc65-435a-4c0e-bdb3-719df37ac9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents.add_lambda_action_group_with_rek(\n",
    "    agent_name=agent_name,\n",
    "    lambda_function_name=lambda_name,\n",
    "    source_code_file=\"detection.py\",\n",
    "    agent_functions=functions_def,\n",
    "    agent_action_group_name=\"key_figure_detection_actions\",\n",
    "    agent_action_group_description=\"Functions to identify key figures and look up cast members and their role from the video\",\n",
    "    env_args=env_args\n",
    ")\n",
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e94f07-0748-474e-9817-7eda0a31af4c",
   "metadata": {},
   "source": [
    "### Loading DynamoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdee1b31",
   "metadata": {},
   "source": [
    "The following step populates the DynamoDB table with information about cast members that can be used to enrich the celebrity detection results. When the Lambda function detects a celebrity in a video, it can look up additional information about that person, such as what film they appeared in and what role they played, which is crucial for accurate film identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fff19f1-753e-4386-a0f7-a37a6211314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read the JSONL file\n",
    "with open('cast_members.jsonl', 'r') as file:\n",
    "    table_items = [json.loads(line.strip()) for line in file]\n",
    "\n",
    "agents.load_dynamodb(cast_table, table_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fa1f35",
   "metadata": {},
   "source": [
    "Now let's test the DynamoDB query functionality for cast member lookup !\n",
    "\n",
    "We will use the specific celebrity ID ('4kn3Xu8r') to look up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1598db1-4560-4d77-9571-bd3078a1a70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = agents.query_dynamodb(\n",
    "    cast_table, cast_pk, '4kn3Xu8r'\n",
    ")\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a17ebd",
   "metadata": {},
   "source": [
    "This test confirms that the DynamoDB table is properly populated and can be queried to retrieve cast member information. The Lambda function will use this same query mechanism to enrich celebrity detection results with film and role information, which is essential for the agent to accurately identify films based on the actors that appear in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcab31ba-e58a-4d0d-9f6b-692c46083791",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store cast_table\n",
    "%store cast_pk\n",
    "%store film_video_s3_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8589e91e-7dfd-43f0-904f-e2242fb56367",
   "metadata": {},
   "source": [
    "### Test Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedf82d1",
   "metadata": {},
   "source": [
    "Let's configure the session state for the agent with video analysis data. \n",
    "\n",
    "This configuration provides the agent with all the information it needs to identify a film:\n",
    "1. The video analysis data for understanding the content\n",
    "2. The video S3 path for celebrity detection\n",
    "3. Access to the knowledge base for film information lookup\n",
    "\n",
    "By including both the analysis results and the S3 path, the agent can use multiple approaches to identify the film - matching the plot details against the knowledge base and detecting celebrities in the video itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18891eb-9bbe-40cf-85a8-98b08628b0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_state = {\n",
    "    'promptSessionAttributes': {\n",
    "        \"<video_analysis>\": json.dumps(video_analysis),\n",
    "        \"<video_s3_path>\": film_video_s3_path,\n",
    "    },\n",
    "    'knowledgeBaseConfigurations': [\n",
    "            {\n",
    "                'knowledgeBaseId': kb_config['kb_id'],\n",
    "                'retrievalConfiguration': {\n",
    "                    'vectorSearchConfiguration': {\n",
    "                        'implicitFilterConfiguration': {\n",
    "                            'metadataAttributes': [\n",
    "                                {\n",
    "                                    'description': 'this is the name of the director',\n",
    "                                    'key': 'Director',\n",
    "                                    'type': 'STRING'\n",
    "                                },\n",
    "                            ],\n",
    "                            'modelArn': \"anthropic.claude-3-5-sonnet-20241022-v2:0\"\n",
    "                        },\n",
    "                        'numberOfResults': 1,\n",
    "                        'overrideSearchType': 'HYBRID'\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "        ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8beb09",
   "metadata": {},
   "source": [
    "And finally, let's test the complete film identification workflow with the agent !\n",
    "\n",
    "The agent will perform several actions:\n",
    "   - Step 1: Analyzing the request and planning the approach\n",
    "   - Step 2: Searching the knowledge base for films matching the plot details\n",
    "   - Step 3: Deciding to verify with celebrity detection\n",
    "   - Step 4: Calling the celebrity detection function and analyzing results\n",
    "   - Final response: Shows the agent's conclusion that the clip is from \"Meridian\" (2016), confirmed by both plot details and the appearance of actors Kevin Kilner and Reid Scott.\n",
    "\n",
    "This test demonstrates the agent's ability to combine multiple sources of information - knowledge base search and celebrity detection - to accurately identify a film from a video clip. The execution trace shows the agent's reasoning process, making the identification process transparent and explainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f64f4-a6b8-4800-bf53-3271f825b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "response = agents.invoke(\n",
    "    input_text=f\"\"\"\n",
    "    Here is a clip extraction:\n",
    "    $prompt_session_attributes.video_analysis$\n",
    "\n",
    "    if needed, here is the s3 location of the video:\n",
    "    $prompt_session_attributes.video_s3_path$\n",
    "    \n",
    "    can you tell me which film is this clip from?\n",
    "    \"\"\", \n",
    "    agent_id=film_agent[0],\n",
    "    enable_trace=True,\n",
    "    session_id=str(uuid.uuid4()),\n",
    "    session_state=session_state\n",
    ")\n",
    "print(\"====================\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e40070-ca2e-4686-a00c-3e761420e442",
   "metadata": {},
   "source": [
    "### Create alias\n",
    "\n",
    "As you can see, you can use your agent with the `TSTALIASID` to complete tasks. \n",
    "However, for multi-agents collaboration it is expected that you first test your agent and only use it once it is fully functional. \n",
    "Therefore to use an agent as a sub-agent in a multi-agent collaboration you first need to create an agent alias and connect it to a new version. \n",
    "\n",
    "Since we've tested and validated our agent, let's now create an alias for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888944ee-4512-4cea-8b33-c2a0cf5e8c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "film_agent_alias_id, film_agent_alias_arn = agents.create_agent_alias(\n",
    "    film_agent[0], 'v2'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a085a3-f535-4baa-a365-867c15368eca",
   "metadata": {},
   "source": [
    "### Saving Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27280c00",
   "metadata": {},
   "source": [
    "Save all the important information about the film agent and its resources for future use in other notebooks or sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ede6d38-59be-43c7-8a96-8a8296a9bf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "film_agent_arn = agents.get_agent_arn_by_name(agent_name)\n",
    "film_agent_id = film_agent[0]\n",
    "film_kb = knowledge_base_name\n",
    "film_agent_name = agent_name\n",
    "film_kb_id = kb_config['kb_id']\n",
    "film_kb_arn = kb_arn\n",
    "film_kb_description = knowledge_base_description\n",
    "film_kb_name = knowledge_base_name\n",
    "film_video_analysis = video_analysis\n",
    "\n",
    "%store film_agent_alias_id\n",
    "%store film_agent_alias_arn\n",
    "%store film_agent_arn\n",
    "%store film_agent_id\n",
    "%store film_kb\n",
    "%store film_agent_name\n",
    "%store film_kb_id\n",
    "%store film_kb_arn\n",
    "%store film_kb_description\n",
    "%store film_kb_name\n",
    "\n",
    "%store film_video_analysis\n",
    "%store film_video_s3_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a845fd-100d-4346-8b77-699e7fe98e92",
   "metadata": {},
   "source": [
    "### Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437e4916-dc1d-43ba-b090-8de199fd9172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agents.delete_agent(agent_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25f238f-1b55-4339-8987-d59ed89f4d5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# kb.delete_kb(knowledge_base_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35183d3b-ef5d-4bb9-9f6c-d28e9c392f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agents.delete_lambda(lambda_function_name=lambda_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcea2e5-6263-465e-a849-e3fe1bbbd05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #delete BDA project\n",
    "# response = bda_client.delete_data_automation_project(\n",
    "#     projectArn=video_project_arn\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3251adba-6c70-43cf-a874-2ed7ecabb3f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
