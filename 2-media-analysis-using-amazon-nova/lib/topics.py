import math
import webvtt
from functools import cmp_to_key
import json

def to_milliseconds(timestamp):
    hh, mm, ss = timestamp.split(':')
    ss, ms = ss.split('.')
    hh, mm, ss, ms = map(int, (hh, mm, ss, ms))
    return (((hh * 3600) + (mm * 60) + ss) * 1000) + ms

def to_hhmmssms(milliseconds):
    hh = math.floor(milliseconds / 3600000)
    mm = math.floor((milliseconds % 3600000) / 60000)
    ss = math.floor((milliseconds % 60000) / 1000)
    ms = math.ceil(milliseconds % 1000)
    return f"{hh:02d}:{mm:02d}:{ss:02d}.{ms:03d}"

def parse_webvtt(file):
    captions = webvtt.read(file)
    captions = [{
        'text': caption.text,
        'start': caption.start,
        'end': caption.end,
        'start_ms': to_milliseconds(caption.start),
        'end_ms': to_milliseconds(caption.end)
    } for caption in captions]

    return captions

# merge chapters just in case there are overlapped timestamps of the chapters
# sort by start time and by end time
def cmp_timestamps(a, b):
    if a['start_ms'] < b['start_ms']:
        return -1
    if a['start_ms'] > b['start_ms']:
        return 1
    return b['end_ms'] - a['end_ms']

def merge_topics(topics):
    """
    Merges related topics points for the given topics based on overlapped conversation timestamps.
    
    Args:
       topics - the source topics to process
    Returns:
       a list of new topics
    """
    # convert timestamp to milliseconds
    for topic in topics:
        start = topic['start']
        end = topic['end']

        start_ms = to_milliseconds(start)
        end_ms = to_milliseconds(end)

        topic['start_ms'] = start_ms
        topic['end_ms'] = end_ms

    topics = sorted(topics, key=cmp_to_key(cmp_timestamps))

    # merge topics if overlap
    merged = [topics[0]]
    for i in range(1, len(topics)):
        prev = merged[-1]
        cur = topics[i]

        prev_start_ms = prev['start_ms']
        prev_end_ms = prev['end_ms']
        cur_start_ms = cur['start_ms']
        cur_end_ms = cur['end_ms']

        if cur_end_ms < prev_start_ms:
            raise Exception('end_ms < start_ms? SHOULD NOT HAPPEN!')

        if cur_start_ms >= prev_end_ms:
            merged.append(cur)
            continue

        # totally overlapped, skip the topic
        if cur_start_ms > prev_start_ms and cur_end_ms < prev_end_ms:
            continue

        # overlapped, merge the topics
        start_ms = prev_start_ms
        if start_ms > cur_start_ms:
            start_ms = cur_start_ms
        
        end_ms = prev_end_ms
        if end_ms < cur_end_ms:
            end_ms = cur_end_ms

        prev_duration = prev_end_ms - prev_start_ms
        cur_duration = cur_end_ms - cur_start_ms

        reason = prev['reason']
        if cur_duration > prev_duration:
            reason = cur['reason']

        new_topic = {
            'reason': reason,
            'start': to_hhmmssms(start_ms),
            'end': to_hhmmssms(end_ms),
            'start_ms': start_ms,
            'end_ms': end_ms
        }

        merged.pop()
        merged.append(new_topic)

    for i in range(0, len(topics)):
        topics[i]['id'] = i

    return topics

def validate_timestamps(topics, captions):
    """
    Validating the timestamp boundaries of the conversations against the WebVtt timestamps. This step is done to 
    ensure the timestamp generated by the LLM aligns with the timestamps in the transcription created by Amazon Transcribe.
    Args:
        topics - the topics with timestamps boundaries (generated by the LLM)
        captions - caption from webVTT.
    Returns:
        collection of topics that aligns with the original content.
    """
    ## collect caption timestamps per topic
    for topic in topics:
        topic_start = topic['start_ms']
        topic_end = topic['end_ms']

        while len(captions) > 0:
            caption = captions[0]

            caption_start = caption['start_ms']
            caption_end = caption['end_ms']

            if caption_start >= topic_end:
                break

            if caption_end <= topic_start:
                captions.pop(0)
                continue

            if abs(topic_end - caption_start) < abs(caption_end - topic_end):
                break

            if 'timestamps' not in topic:
                topic['timestamps'] = []
            topic['timestamps'].append([caption_start, caption_end])

            captions.pop(0)

    ## align the topic boundary timestamps with the caption timestamps
    for topic in topics:
        if 'timestamps' not in topic:
            continue
        
        topic_start = topic['start_ms']
        topic_end = topic['end_ms']

        caption_start = topic['timestamps'][0][0]
        caption_end = topic['timestamps'][-1][1]

        if topic_start != caption_start:
            topic['start_ms'] = caption_start
            topic['start'] = to_hhmmssms(caption_start)

        if topic_end != caption_end:
            topic['end_ms'] = caption_end
            topic['end'] = to_hhmmssms(caption_end)

        del topic['timestamps']

    return topics




class Topics:
    def __init__(self, conversations, scenes):
       self.topics = align_scenes_in_topics(self, conversations, scenes)

    def align_scenes_in_topics(self, conversations, scenes, frames):
        scenes = copy.deepcopy(shots)
    
        topics = []
        for conversation in conversations['topics']:
            start_ms = conversation['start_ms']
            end_ms = conversation['end_ms']
            text = conversation['reason']

            # find all the frames that align with the conversation topic
            stack = []
            while len(scenes) > 0:
                scene = scenes[0]
                frame_start = scene['start_ms']
                frame_end = scene['end_ms']
    
                if frame_start > end_ms:
                    break
    
                # scenes before any conversation starts
                if frame_end < start_ms:
                    topic = make_topic_item(len(topics), [scene])
                    topics.append(topic)
                    scenes.pop(0)
                    continue
    
                stack.append(scene)
                scenes.pop(0)
    
            if stack:
                topic = make_topic_item(len(topics), stack, text)
                topics.append(topic)
    
        ## There could be more scenes without converations, append them
        for scene in scenes:
            topic = make_topic_item(len(topics), [scene])
            topics.append(topic)
    
        return topics

    def make_topic_item(self,topic_id, scene_items, text = ''):
        scene_ids = [scene['scene_id'] for scene in scene_items]
        return {
            'id': topic_id,
            'scene_ids': [min(scene_ids), max(scene_ids)],
            'text': text,
    }
